import fs from 'fs';
import path from 'path';
import sqlite3 from 'better-sqlite3';
import { DATABASE_DDL } from './ddl/definitions';

export class BackupService {
  private static readonly LOCAL_DB_PATH = path.resolve(process.cwd(), 'local.db');

  static async initialize() {
    console.log("ğŸ› ï¸ [BackupService] Initializing...");
    const backupsDir = path.resolve(process.cwd(), 'backups');
    if (!fs.existsSync(backupsDir)) {
      fs.mkdirSync(backupsDir, { recursive: true });
    }
  }

  static startAutoBackupScheduler() {
    console.log("â° [BackupService] Auto backup scheduler started");
    const intervalHours = Number(process.env.BACKUP_INTERVAL_HOURS) || 6;
    const intervalMs = intervalHours * 60 * 60 * 1000;
    setInterval(async () => {
      console.log("â° [BackupService] Running scheduled auto backup...");
      await this.runBackup();
    }, intervalMs);
  }

  private static async getAllTables(): Promise<string[]> {
    try {
      const { pool } = await import('../db');
      // Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª PostgreSQL
      const result = await pool.query(`
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_type = 'BASE TABLE'
      `);
      
      const tables = result.rows.map(row => row.table_name);
      
      if (tables.length > 0) {
        console.log(`ğŸ“‹ [BackupService] Found ${tables.length} tables in database:`, tables);
        return tables;
      }
    } catch (error: any) {
      console.warn("âš ï¸ [BackupService] Error fetching tables from DB:", error.message);
    }

    // fallback Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
    return ['users', 'projects', 'workers', 'suppliers', 'materials', 'wells', 'well_expenses', 'audit_logs', 'notifications'];
  }

  static async runBackup() {
    try {
      console.log("ğŸ’¾ [BackupService] Starting complete PostgreSQL backup...");
      const backupsDir = path.resolve(process.cwd(), 'backups');
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const backupPath = path.join(backupsDir, `backup-${timestamp}.json`);
      const tables = await this.getAllTables();
      const backupData: Record<string, any[]> = {};
      const { pool } = await import('../db');
      
      let tablesSuccessfullyBackedUp = 0;
      for (const tableName of tables) {
        try {
          // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª Ù…Ø²Ø¯ÙˆØ¬Ø© Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø³Ø§Ø³Ø©
          console.log(`ğŸ” [BackupService] Querying table: ${tableName}`);
          const result = await pool.query(`SELECT * FROM "${tableName}"`);
          backupData[tableName] = result.rows;
          tablesSuccessfullyBackedUp++;
          console.log(`âœ… [BackupService] Backed up table: ${tableName} (${result.rows.length} rows)`);
        } catch (e: any) {
          console.error(`âŒ [BackupService] Failed to back up table ${tableName}:`, e.message);
        }
      }

      const totalRows = Object.values(backupData).reduce((acc, rows) => acc + rows.length, 0);
      fs.writeFileSync(backupPath, JSON.stringify({
        timestamp: new Date().toISOString(),
        version: "1.2",
        totalRows,
        tablesCount: tablesSuccessfullyBackedUp,
        data: backupData
      }, null, 2));

      console.log(`ğŸ [BackupService] Backup completed: ${backupPath} (Total rows: ${totalRows})`);

      return { 
        success: true, 
        message: `ØªÙ… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù€ ${tablesSuccessfullyBackedUp} Ø¬Ø¯ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­`, 
        path: backupPath,
        totalRows 
      };
    } catch (error: any) {
      console.error("âŒ [BackupService] Backup failed:", error);
      return { success: false, message: error.message };
    }
  }

  static async analyzeDatabase(target: 'local' | 'cloud') {
    try {
      const { pool } = await import('../db');
      const tables = await this.getAllTables();
      const report = [];
      const sqlite = target === 'local' ? new sqlite3(this.LOCAL_DB_PATH) : null;
      
      for (const table of tables) {
        let exists = false;
        if (target === 'cloud') {
          const res = await pool.query(`SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = $1)`, [table]);
          exists = res.rows[0].exists;
        } else if (sqlite) {
          const res = sqlite.prepare(`SELECT name FROM sqlite_master WHERE type='table' AND name=?`).get(table);
          exists = !!res;
        }
        report.push({ table, status: exists ? 'exists' : 'missing' });
      }
      if (sqlite) sqlite.close();
      return { success: true, report };
    } catch (error: any) {
      return { success: false, message: error.message };
    }
  }

  static async createMissingTables(target: 'local' | 'cloud', tablesToCreate: string[]) {
    try {
      if (target === 'cloud') {
        const { pool } = await import('../db');
        const client = await pool.connect();
        try {
          await client.query('BEGIN');
          for (const table of tablesToCreate) {
            const ddl = DATABASE_DDL[table];
            if (ddl) {
              await client.query(ddl);
            }
          }
          await client.query('COMMIT');
        } catch (e) {
          await client.query('ROLLBACK');
          throw e;
        } finally {
          client.release();
        }
      } else {
        const db = new sqlite3(this.LOCAL_DB_PATH);
        db.transaction(() => {
          for (const table of tablesToCreate) {
            let ddl = DATABASE_DDL[table];
            if (ddl) {
              // Convert PG DDL to SQLite compatible
              ddl = ddl.replace(/SERIAL PRIMARY KEY/gi, 'INTEGER PRIMARY KEY AUTOINCREMENT')
                       .replace(/gen_random_uuid\(\)/gi, '(lower(hex(randomblob(16))))')
                       .replace(/JSONB/gi, 'TEXT')
                       .replace(/TIMESTAMP/gi, 'DATETIME')
                       .replace(/DECIMAL\(\d+,\d+\)/gi, 'REAL');
              db.exec(ddl);
            }
          }
        })();
        db.close();
      }
      return { success: true, message: `ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ${tablesToCreate.length} Ø¬Ø¯ÙˆÙ„ Ù…ÙÙ‚ÙˆØ¯ Ø¨Ù†Ø¬Ø§Ø­` };
    } catch (error: any) {
      console.error("âŒ [BackupService] Table creation failed:", error);
      return { success: false, message: error.message };
    }
  }

  static async listAutoBackups() {
    try {
      const backupsDir = path.resolve(process.cwd(), 'backups');
      if (!fs.existsSync(backupsDir)) return { success: true, logs: [] };
      const files = fs.readdirSync(backupsDir);
      const logs = files
        .filter(f => (f.startsWith('backup-') && (f.endsWith('.json') || f.endsWith('.db'))) || f.startsWith('manual_backup_'))
        .map((f, index) => {
          try {
            const filePath = path.join(backupsDir, f);
            const stats = fs.statSync(filePath);
            return {
              id: index + 1,
              filename: f,
              size: (stats.size / (1024 * 1024)).toFixed(2),
              status: 'success',
              createdAt: stats.mtime.toISOString(),
              destination: f.endsWith('.json') ? 'Local/Cloud' : 'Local'
            };
          } catch (e) {
            return null;
          }
        })
        .filter((log): log is any => log !== null)
        .sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());
      
      return { success: true, logs };
    } catch (error: any) {
      console.error("âŒ [BackupService] Error listing backups:", error);
      return { success: false, message: error.message, logs: [] };
    }
  }

  static getAutoBackupStatus() {
    return {
      isEnabled: true,
      intervalHours: Number(process.env.BACKUP_INTERVAL_HOURS) || 6,
      lastRun: new Date().toISOString(), // In a real scenario, this would be tracked in storage
      status: "active"
    };
  }

  static async getAvailableDatabases() {
    const dbs = [];
    const envContent = fs.readFileSync(path.resolve(process.cwd(), '.env'), 'utf8');
    
    // Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ DATABASE_URL_
    // Use a standard while loop to avoid --downlevelIteration issues with matchAll
    const regex = /DATABASE_URL_([a-zA-Z0-9_]+)=(.+)/g;
    let match;
    while ((match = regex.exec(envContent)) !== null) {
      dbs.push({
        id: match[1].toLowerCase(),
        name: match[1].replace(/_/g, ' '),
        url: match[2].trim()
      });
    }

    // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
    if (!dbs.find(d => d.id === 'central')) {
      const centralUrl = process.env.DATABASE_URL_CENTRAL;
      if (centralUrl) {
        dbs.push({ id: 'central', name: 'Central DB', url: centralUrl });
      }
    }
    
    return dbs.filter(d => d.url);
  }

  static async testConnection(target: string) {
    try {
      let targetUrl = '';
      if (target === 'central') {
        targetUrl = process.env.DATABASE_URL_CENTRAL || '';
      } else {
        const dbs = await this.getAvailableDatabases();
        const db = dbs.find(d => d.id === target.toLowerCase());
        if (db) targetUrl = db.url;
      }

      if (!targetUrl) throw new Error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„Ø§ØªØµØ§Ù„");

      const { Pool } = await import('pg');
      const testPool = new Pool({ 
        connectionString: targetUrl,
        connectionTimeoutMillis: 5000 
      });
      
      const client = await testPool.connect();
      await client.query('SELECT 1');
      client.release();
      await testPool.end();

      return { success: true, message: "ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©" };
    } catch (error: any) {
      return { success: false, message: `ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: ${error.message}` };
    }
  }

  static async restoreBackup(filename: string, target: string) {
    try {
      const backupPath = path.join(process.cwd(), 'backups', filename);
      if (!fs.existsSync(backupPath)) throw new Error("Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯");
      
      const content = fs.readFileSync(backupPath, 'utf8');
      const { data } = JSON.parse(content);
      
      // ØªØ­Ø¯ÙŠØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
      let targetPool;
      if (target === 'local' || target === 'central') {
        const { pool } = await import('../db');
        targetPool = pool;
      } else {
        // Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ù† .env Ù„Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
        const dbs = await this.getAvailableDatabases();
        const selectedDb = dbs.find(d => d.id === target.toLowerCase());
        if (!selectedDb) throw new Error(`Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ${target} ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©`);
        
        const { Pool } = await import('pg');
        targetPool = new Pool({ connectionString: selectedDb.url });
      }

      const client = await targetPool.connect();
      try {
        await client.query('BEGIN');
        await client.query('SET CONSTRAINTS ALL DEFERRED');
        
        // Ø¬Ù„Ø¨ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        const backupTables = Object.keys(data);

        for (const tableName of backupTables) {
          try {
            const tableNameLower = tableName.toLowerCase();
            const tableRes = await client.query(`SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = $1)`, [tableNameLower]);
            if (!tableRes.rows[0].exists) {
              console.warn(`âš ï¸ [BackupService] Table ${tableName} does not exist in target DB, skipping...`);
              continue;
            }
            await client.query(`TRUNCATE TABLE "${tableNameLower}" RESTART IDENTITY CASCADE`);
          } catch (e: any) {
            console.error(`âŒ [BackupService] Error truncating table ${tableName}:`, e.message);
          }
        }
        
        for (const [tableName, rows] of Object.entries(data as Record<string, any[]>)) {
          try {
            if (rows.length === 0) continue;
            const tableNameLower = tableName.toLowerCase();
            
            const columns = Object.keys(rows[0]).map(c => `"${c}"`).join(', ');
            for (const row of rows) {
              const values = Object.values(row);
              const placeholders = values.map((_, i) => `$${i + 1}`).join(', ');
              await client.query(`INSERT INTO "${tableNameLower}" (${columns}) VALUES (${placeholders})`, values);
            }
          } catch (e: any) {
            console.error(`âŒ [BackupService] Error restoring table ${tableName}:`, e.message);
          }
        }
        await client.query('COMMIT');
      } catch (e) {
        await client.query('ROLLBACK');
        throw e;
      } finally {
        client.release();
        if (target !== 'local' && target !== 'central') await targetPool.end();
      }

      return { success: true, message: "ØªÙ…Øª Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨Ù†Ø¬Ø§Ø­" };
    } catch (error: any) {
      console.error("âŒ [BackupService] Restore failed:", error);
      return { success: false, message: error.message };
    }
  }
}
